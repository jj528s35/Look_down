{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pyzed.sl as sl\n",
    "import cv2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import get_clear_hand_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Dis_pt2plane(pts, a, b, c, d):\n",
    "#     \"\"\"\n",
    "#     Compute the distance from points to the plane\n",
    "#     \"\"\"\n",
    "#     normal = math.sqrt(a*a+b*b+c*c)\n",
    "#     if normal == 0:\n",
    "#         normal = 1\n",
    "    \n",
    "#     v = np.array([a,b,c])\n",
    "#     dis = abs(np.dot(pts,v.T)+d)/normal\n",
    "#     return dis\n",
    "\n",
    "# def get_Plane(sampts):\n",
    "#     \"\"\"\n",
    "#     Compute the equation of the plane\n",
    "#     \"\"\"\n",
    "#     p1 = sampts[0]\n",
    "#     p2 = sampts[1]\n",
    "#     p3 = sampts[2]\n",
    "    \n",
    "#     a = ( (p2[1]-p1[1])*(p3[2]-p1[2])-(p2[2]-p1[2])*(p3[1]-p1[1]) )\n",
    "#     b = ( (p2[2]-p1[2])*(p3[0]-p1[0])-(p2[0]-p1[0])*(p3[2]-p1[2]) )\n",
    "#     c = ( (p2[0]-p1[0])*(p3[1]-p1[1])-(p2[1]-p1[1])*(p3[0]-p1[0]) )\n",
    "#     d = ( 0-(a*p1[0]+b*p1[1]+c*p1[2]) )\n",
    "    \n",
    "#     return a,b,c,d\n",
    "\n",
    "# def Random3points(points3D, ConfidenceIndex):\n",
    "#     \"\"\"\n",
    "#     Random choose 3 Confidence points\n",
    "#     \"\"\"\n",
    "#     sample_number = 3\n",
    "#     sample_point_index = random.sample(range(ConfidenceIndex.shape[0]), sample_number)\n",
    "#     sample_points = np.zeros((sample_number,3))\n",
    "#     for i in range(sample_number):\n",
    "#         Confidence_point_index = sample_point_index[i]\n",
    "#         index = ConfidenceIndex[Confidence_point_index]\n",
    "#         y = index[0]\n",
    "#         x = index[1]\n",
    "#         sample_points[i] = points3D[y][x]\n",
    "#     return sample_points\n",
    "\n",
    "# # def Random3points(points3D):\n",
    "# #     sample_number = 3\n",
    "# #     sample_point_index = random.sample(range(points3D.shape[0]*points3D.shape[1]), sample_number)\n",
    "# #     sample_points = np.zeros((sample_number,3))\n",
    "# #     for i in range(sample_number):\n",
    "# #         index = sample_point_index[i]\n",
    "# #         y = index // points3D.shape[1]\n",
    "# #         x = index % points3D.shape[1]\n",
    "# #         sample_points[i] = points3D[y][x]\n",
    "# #     return sample_points\n",
    "\n",
    "# def get_inliner_num(points3D,a,b,c,d,inliner_threshold):\n",
    "#     \"\"\"\n",
    "#     Compute the liner points which distance to plane < threshold\n",
    "#     Also get distance from points to the plane (new Depth Image which re-project depth pixels in surface plane)\n",
    "#     \"\"\"\n",
    "#     inliner_num = 0\n",
    "    \n",
    "#     dist = Dis_pt2plane(points3D,a,b,c,d)\n",
    "#     inliner_mask = dist < inliner_threshold\n",
    "#     inliner_num = np.sum(inliner_mask)\n",
    "#     return inliner_num, inliner_mask, dist\n",
    "\n",
    "# def RANSAM(points3D, ConfidenceIndex, ransac_iteration = 500, inliner_threshold = 10):\n",
    "#     best_inlinernum = -1\n",
    "#     best_inlinernum = 0\n",
    "#     best_plane = np.zeros((1,4))\n",
    "#     best_depthImage = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "#     best_plane_mask = np.zeros((points3D.shape[0],points3D.shape[1]))\n",
    "# #     best_sampts = np.zeros((3,3))\n",
    "    \n",
    "# #     print(points3D.shape,points3D[80:90,110])\n",
    "#     for i in range(ransac_iteration):\n",
    "#         sampts = Random3points(points3D, ConfidenceIndex)\n",
    "#         a,b,c,d = get_Plane(sampts)\n",
    "        \n",
    "#         inliner_num, inliner_mask, depthImage = get_inliner_num(points3D,a,b,c,d,inliner_threshold)\n",
    "#         if(inliner_num > best_inlinernum):\n",
    "#             best_inlinernum = inliner_num\n",
    "#             best_plane = np.array([a,b,c,d])\n",
    "#             best_plane_mask = inliner_mask\n",
    "#             best_depthImage = depthImage\n",
    "# #             best_sampts = sampts\n",
    "\n",
    "#         if (best_inlinernum > 480000):\n",
    "#             print(\"Inliner Number\\n\", best_inlinernum)\n",
    "#             print(\"Inliner plane\\n\", best_plane)\n",
    "#             return best_plane, best_depthImage, best_plane_mask\n",
    "            \n",
    "            \n",
    "#     print(\"Inliner Number\\n\", best_inlinernum)\n",
    "#     print(\"Inliner plane\\n\", best_plane)\n",
    "#     return best_plane, best_depthImage, best_plane_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candy_edge_with_skin_detect(image):\n",
    "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb) # 把圖像轉換到YUV色域\n",
    "    (y, cr, cb) = cv2.split(ycrcb) # 圖像分割, 分別獲取y, cr, br通道圖像\n",
    "    # 高斯濾波, cr 是待濾波的源圖像數據, (5,5)是值窗口大小, 0 是指根據窗口大小來計算高斯函數標準差\n",
    "    cr1 = cv2.GaussianBlur(cr, (5, 5), 0) # 對cr通道分量進行高斯濾波\n",
    "    # 根據OTSU算法求圖像閾值, 對圖像進行二值化_, \n",
    "    _ ,skin1 = cv2.threshold(cr1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) \n",
    "    cv2.imshow(\"Skin Cr+OSTU\", skin1 )\n",
    "    return skin1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    init = sl.InitParameters()\n",
    "    init.camera_resolution = sl.RESOLUTION.RESOLUTION_HD720\n",
    "    init.depth_mode = sl.DEPTH_MODE.DEPTH_MODE_PERFORMANCE\n",
    "\n",
    "    #read from streaming\n",
    "#     sys.argv[1] = '127.0.0.1'\n",
    "#     if (len(sys.argv) > 1) :\n",
    "#         ip = sys.argv[1]\n",
    "#         init.set_from_stream(ip)\n",
    "#     else :\n",
    "#         print('Usage : python3 streaming_receiver.py ip')\n",
    "#         exit(1)\n",
    "        \n",
    "    #read from SVO file\n",
    "    filepath = 'record_1017_1.svo'\n",
    "    print(\"Reading SVO file: {0}\".format(filepath))\n",
    "\n",
    "    init = sl.InitParameters(svo_input_filename=filepath,svo_real_time_mode=False)\n",
    "    init.depth_minimum_distance = 150 # Set the minimum depth perception distance to 15cm\n",
    "#     print(init.depth_mode)#PERFORMANCE\n",
    "\n",
    "    cam = sl.Camera()\n",
    "    status = cam.open(init)\n",
    "    if status != sl.ERROR_CODE.SUCCESS:\n",
    "        print(repr(status))\n",
    "        exit(1)\n",
    "\n",
    "    runtime = sl.RuntimeParameters()\n",
    "#     runtime.sensing_mode = sl.SENSING_MODE.SENSING_MODE_FILL \n",
    "    \n",
    "    image = sl.Mat() #image\n",
    "    depth = sl.Mat() #depth map\n",
    "    depth_for_display = sl.Mat() #depth map,scale its values to [0, 255]\n",
    "    point_cloud = sl.Mat() #colored point cloud.\n",
    "    confidence_map = sl.Mat() # confidence_map  [0 ,100], 0 :the best confidence value; 100 :the most unconfident one.\n",
    "\n",
    "    key = ''\n",
    "    First = True\n",
    "    print(\"  Quit : CTRL+C\\n\")\n",
    "    while key != 113:\n",
    "        err = cam.grab(runtime)\n",
    "        if (err == sl.ERROR_CODE.SUCCESS) :\n",
    "            # Retrieve left image\n",
    "            cam.retrieve_image(image, sl.VIEW.VIEW_LEFT)\n",
    "            cam.retrieve_image(depth_for_display, sl.VIEW.VIEW_DEPTH)\n",
    "            \n",
    "            # Load Image data into a numpy array\n",
    "            RGB_image = image.get_data()\n",
    "            gray_image = cv2.cvtColor(RGB_image, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            \n",
    "            # Retrieve depth map. Depth is aligned on the left image\n",
    "            cam.retrieve_measure(depth, sl.MEASURE.MEASURE_DEPTH)\n",
    "            # Load depth data into a numpy array\n",
    "            depth_data = depth.get_data()\n",
    "            \n",
    "            # Retrieve colored point cloud. Point cloud is aligned on the left image.\n",
    "            cam.retrieve_measure(point_cloud, sl.MEASURE.MEASURE_XYZRGBA)\n",
    "            # Load point cloud into a numpy array\n",
    "            points3D_color = point_cloud.get_data()\n",
    "            points3D = points3D_color[:,:,:3] # only need x,y,z \n",
    "            points3D = np.where(points3D == np.nan, 1111, points3D)# replace nan to 1111111\n",
    "            \n",
    "            \n",
    "            #get confidence index : index which value is not NAN \n",
    "            Confidence_index = np.argwhere(~np.isnan(depth_data))\n",
    "            \n",
    "#             # Retrieve confidence_map.\n",
    "#             cam.retrieve_measure(confidence_map, sl.MEASURE.MEASURE_CONFIDENCE)\n",
    "#             # Load confidence_map into a numpy array\n",
    "#             confidence_img = confidence_map.get_data()\n",
    "#             confidence_index = np.argwhere(confidence_img <= 60)\n",
    "\n",
    "            \n",
    "            #####\n",
    "            if First == True:\n",
    "                #RANSAM to get surface plane\n",
    "                surface_plane, depthImg, plane_mask = get_clear_hand_mask.RANSAM(points3D, Confidence_index, ransac_iteration = 500, inliner_threshold = 10)\n",
    "                First = False\n",
    "                print(\"firstly RANSAM\")\n",
    "            else:\n",
    "                #\n",
    "                depthImg = get_clear_hand_mask.get_depth_map(points3D, surface_plane)\n",
    "                #Canny edge map(infrared image) + threshold based edge map(depth image)\n",
    "                Cannyedges, Threshold_based_edge, Edge_map, grayImage = get_clear_hand_mask.get_edge_map(gray_image, depthImg)\n",
    "#                 Test skin_detect than Canny edge\n",
    "#                 skinImg = candy_edge_with_skin_detect(RGB_image)\n",
    "\n",
    "#                 #Get hight region by Hight and record its position\n",
    "#                 High_region_Image, high_region_list = get_clear_hand_mask.get_high_region(depthImg)\n",
    "#                 #Get Hand mask by Flood fill from high region position with Edge map\n",
    "#                 Hand_mask_Image = get_clear_hand_mask.get_Hand_mask(Edge_map, high_region_list, High_region_Image)\n",
    "#                 #\n",
    "#                 cnt, contours_image, hand_center, fingertips = find_fingertip(Hand_mask_Image)\n",
    "#                 # tracking user hand and fingertips\n",
    "#                 hand_tracking(hand_center, fingertips)\n",
    "            \n",
    "            #####\n",
    "                #Check result\n",
    "#                 cv2.imshow(\"Depth\", depthImg)\n",
    "                cv2.imshow(\"plane_mask\", plane_mask.astype(np.uint8)*255)\n",
    "#                 cv2.imshow(\"Cannyedges\", Cannyedges)\n",
    "#                 cv2.imshow(\"Edge_map\", Threshold_based_edge.astype(np.uint8)*255)\n",
    "                #Candy edge => detect skin or replace the table color\n",
    "#                 cv2.imshow(\"High_region_Image\", High_region_Image)\n",
    "                \n",
    "#                 cv2.imshow(\"ZED_gray\", grayImage)\n",
    "    \n",
    "            cv2.imshow(\"ZED\", RGB_image)\n",
    "            cv2.imshow(\"Depth img\", depth_for_display.get_data())\n",
    "\n",
    "            key = cv2.waitKey(1)\n",
    "        else :\n",
    "            key = cv2.waitKey(1)\n",
    "\n",
    "    cam.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading SVO file: record_1017_1.svo\n",
      "  Quit : CTRL+C\n",
      "\n",
      "Inliner Number\n",
      " 453177\n",
      "Inliner plane\n",
      " [ 2.14107363e+02 -2.04562952e+03 -4.31223290e+03  1.35807784e+06]\n",
      "firstly RANSAM\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-972361fa1b80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-d13cea515471>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mdepthImg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_clear_hand_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_depth_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints3D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msurface_plane\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[1;31m#Canny edge map(infrared image) + threshold based edge map(depth image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 \u001b[0mCannyedges\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mThreshold_based_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEdge_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrayImage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_clear_hand_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_edge_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdepthImg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;31m#                 #Get hight region by Hight and record its position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m                 \u001b[1;31m#Test skin_detect than Canny edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\HMD_Look_down\\get_clear_hand_mask.py\u001b[0m in \u001b[0;36mget_edge_map\u001b[1;34m(grayImage, depthImage)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[0mThreshold_based_edge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mThreshold_based_edge\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_depth_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;31m#check up depth threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m     \u001b[0mdepth_img_transform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepthImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m     \u001b[0mdepth_img_transform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdepthImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[0mcheck_depth_threshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepthImage\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdepth_img_transform\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdepthImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdepthImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mnear_depth_threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
